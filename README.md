# webscraping_textprocessing
Basic web scraping &amp; text processing in Python

In this python code, I covered the following: 

**Part I: Web Scraping**
Crawled data from html webpage 

**Part II: Text Processing** 
The data preprocessing steps for this exercise includes the following:
•	Tokenization — separating text/string data into units (paragraphs, sentences or words)
•	Text Normalization — converting all letters to lower or upper case, removing unnecessary punctuation, empty strings
•	Removing stop words — frequent words such as ”the”, ”is”, etc. that do not have specific semantic
•	Lemmatization — reduce words with different forms like 'loves', 'loving', 'lovely' to a common base form or root word 'love'.

**Part III: Basic Visualisation for tokenized words**
Frequency distribution graph and word cloud

